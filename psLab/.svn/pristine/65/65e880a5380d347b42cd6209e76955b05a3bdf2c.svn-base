{

  bool RELOAD;

    RELOAD = true;
    gROOT->Macro("$LAB_MAIN_DIR/llhTimeDep/loadlibs.C");
    if (!LOADSUCCESS) { return 0.; } // stop, and signal that script failed.

  //  TString macroPath = gROOT->GetMacroPath();
  //  macroPath += gSystem->ExpandPathName("$LAB_MAIN_DIR/macro_llh:");
  //  gROOT->SetMacroPath(macroPath);


    if (0) { initialize_ran1(-55); } // seed has to be a *NEGATIVE* integer
    else   { initialize_ran1(); }  // or, no seed = initialize to ran clock time
    int ranSeed = get_ran1_seed(); // if you want to know what the seed was

    gROOT->ProcessLine(".L $LAB_MAIN_DIR/macro_llh/ic59/Ark.C");

    bool OPT_USEREALDATA = false;

//    I3Ark ark22;
//    gROOT->ProcessLine(".x load_ark_ic22.C(ark22, OPT_USEREALDATA)");

    I3Ark ark40;
    gROOT->ProcessLine(".x $LAB_MAIN_DIR/macro_llh/ic59/load_ark_ic40_2075.C(ark40, OPT_USEREALDATA)");
    //gROOT->ProcessLine(".x $LAB_MAIN_DIR/macro_llh/ic59/load_ark_ic40.C(ark40, OPT_USEREALDATA)");

    I3Ark ark59;
    gROOT->ProcessLine(".x $LAB_MAIN_DIR/macro_llh/ic59/load_ark_ic59_onetenth.C(ark59, OPT_USEREALDATA)");

  //gROOT->ProcessLine(".L AllSky.C");
  //AllSky as;
  //as.SetRange(148, 158, 5, 15);

    MultiArk mark;
    //mark.AddArk(ark22);
    mark.AddArk(ark40);
    mark.AddArk(ark59);
    
    MultiAnalysisSet* mas = dynamic_cast<MultiAnalysisSet*>(mark.psData);

    int monLev = 0;

    // Specific to UHECR:
    printf("Setting up Stacking Analysis Sources (UHECR)...\n");

    bool OPT_LOADSIGNAL = true;

    I3MultiSignalGenerator msg40;
    I3MultiSignalGenerator msg59;
    vector<I3Event> sourceEvents;

    double spectralIndex = -2; //for injection, for llh, this is fitted 
    PowerLawFlux pflux(1,spectralIndex); // 1 GeV^-1 cm^-2 s^-1;  index = configurable

    int nUHECRListExpected = 82; // Just a precaution // Just a precaution
    int nUHECRList = 0;

    char* inFilename = "stacking/UHECR/UHECR.txt";

    // Can configure analysis to use a weight, defaults to false
    bool OPT_USE_THEORY_WEIGHT_SOURCE = false;  // Source Simulation Weight
    bool OPT_USE_THEORY_WEIGHT_SEARCH = false;  // Search Hypothesis Weight
    
    printf("Weight source simulation: %i\n",
         OPT_USE_THEORY_WEIGHT_SOURCE);
    printf("Weight search hypothesis: %i\n",
         OPT_USE_THEORY_WEIGHT_SEARCH);
    
    ifstream in;
    in.open(inFilename);

    char buffer[100];
    double raDeg, decDeg;
    char sourceName[20];
    double dummy=0;

    // Source locations, read from txt file
    vector<EquatorialDeg> srcLocations;
    srcLocations.clear();
 
    // Theoretical enhancements for I3MultiSignalGenerator signal generation
    vector<double> enhancementFactors;
    enhancementFactors.clear();
 
    // Size of sources (all point-sources here)
    vector<double> srcSigmas;
    srcSigmas.clear();
 
    // Search enhancements for likelihood pdfs
    vector<double> pdfEnhancements;
    pdfEnhancements.clear();
 
    // Read the UHECR catalogue, store all info in vectors
    int srcIndex=0;
    while (1){
      in >> raDeg >> decDeg >> sourceName;
      if ( !in.good() ) break;
      //printf("%03d:, Name= %14s, RA= %3.2f, Dec= %3.2f Flux60um= %4.2f\n",srcIndex,buffer,raDeg,decDeg,Flux60um);
      printf("%0.2f %0.2f %s\n",raDeg,decDeg,sourceName);
 
      srcLocations.push_back( EquatorialDeg(raDeg, decDeg) );
      srcSigmas.push_back(3.0); // all treated with same 3.0deg extension
 
      // These vectors are normalized a bit later
      if (OPT_USE_THEORY_WEIGHT_SOURCE) { enhancementFactors.push_back(1.); }
      else { enhancementFactors.push_back(1.); }
      if (OPT_USE_THEORY_WEIGHT_SEARCH) { pdfEnhancements.push_back(1.);}
      else { pdfEnhancements.push_back(1.); }
 
      ++srcIndex;
      //cout << srcIndex << " " << flush;
    }
    nUHECRList = srcIndex;

    // At least make sure vector lengths are same size
    assert ( nUHECRList == nUHECRListExpected );
    assert ( nUHECRList == srcLocations.size());
    assert ( srcSigmas.size() == srcLocations.size() ); // else misconfigured
    assert ( enhancementFactors.size() == srcLocations.size() ); // else misconfigured
    assert ( pdfEnhancements.size() == srcLocations.size() ); // else misconfigured
 
    cout << nUHECRList << " total UHECR sources read.\n";
    //fclose(fp);
    in.close();

    // Normalize the enhancement factors (easier to interpret final flux)
    double sumEF=0;
    double sumPE=0;
    for (int i=0; i<nUHECRList; i++){
      sumEF += enhancementFactors[i];
      sumPE += pdfEnhancements[i];
    }
    for (int i=0; i<nUHECRList; i++){
      enhancementFactors[i]/=sumEF;
      pdfEnhancements[i]/=sumPE;
    }

    // Each Ark has its own event loader.  Each ark needs its own msg... 
    //  (I.e. its own list of candidate source events)
    EventLoaderExt evLoader40 = dynamic_cast<const EventLoaderExt&>(ark40.evLoader);
    evLoader40.SetNUpSamples(20); // Default number of times each signal event is moved
    EventLoaderExt evLoader59 = dynamic_cast<const EventLoaderExt&>(ark59.evLoader);
    evLoader59.SetNUpSamples(20); // Default number of times each signal event is moved
    srcIndex = 0;

    // Loop again, adding source to I3MultiSignalGenerator
    cout << "Loading Source Events... (This may take a while)\n";
    srcIndex=0;
    if (OPT_LOADSIGNAL){
      for (int i=0; i<nUHECRList; i++){
        //printf("%03d %6.2f %6.2f %5.2f, %5.2f\n",srcIndex,srcLocations[srcIndex]->GetRa(),srcLocations[srcIndex]->GetDec(),enhancementFactors[srcIndex],pdfEnhancements[srcIndex]);
        evLoader40.LoadSourcePdf_Kent(srcLocations[srcIndex], srcSigmas[srcIndex]);
        evLoader40.LoadSourceEvents(sourceEvents);
        I3PointGenerator i3point(sourceEvents, pflux, srcLocations[srcIndex], ark40.livetime);
        msg40.AddSignal(i3point,enhancementFactors[srcIndex]);

        evLoader59.LoadSourcePdf_Kent(srcLocations[srcIndex], srcSigmas[srcIndex]);
        evLoader59.LoadSourceEvents(sourceEvents);
        I3PointGenerator i3point(sourceEvents, pflux, srcLocations[srcIndex], ark59.livetime);
        msg59.AddSignal(i3point,enhancementFactors[srcIndex]);

        cout << "." << flush;
        srcIndex++;
      }
    }
    cout << endl;

    // ... finished adding sources
 
    I3SignalGenerator *mySignalPtr40 = &msg40;
    SourceModule *srcMod40 = mySignalPtr40; // one more base class deep
 
    I3SignalGenerator *mySignalPtr59 = &msg59;
    SourceModule *srcMod59 = mySignalPtr59;
 
 
    // CALCULATE STACKING WEIGHTS VS GAMMA TABLE
    // Set theoretical bias, i.e. if you have reason to believe one source emits 
    //  a higher flux, add that enhancement factor here and the stacking search
    //  will use that enhancement factor to construct the signal spatial pdfs
    //  e.g., if you believe one source emits twice as much flux as another, the 
    //  srcWeightsArray will scale that source pdf up by a factor of 2 if set here.
    //  (It will not inject more flux, such as setting the enhancement factor
    //   of the I3PointGenerator)
 
    // At least make sure these are the same length as number of sources
    assert ( srcSigmas.size() == srcLocations.size() ); // else misconfigured
    assert ( enhancementFactors.size() == srcLocations.size() ); // else misconfigured
    assert ( pdfEnhancements.size() == srcLocations.size() ); // else misconfigured

    cout << "\nCalculating Stacking Weight vs Gamma Tables...\n ";
 
    double gammaMin = -4;
    double gammaMax = -1;
    int nGammaBins  = 30;
 
 
    vector<vector<double> > srcWeightsArray40;
    int vSize = srcLocations.size();
    srcWeightsArray40.resize( vSize );
    double srcWeight=0, testGamma=0;
    for (int srcIndex=0; srcIndex < srcLocations.size(); srcIndex++) {
 
      evLoader40.LoadSourceEvents(sourceEvents, srcLocations[srcIndex]);
 
      for ( int gammaIndex=0; gammaIndex<nGammaBins; gammaIndex++) {
        double testGamma = (gammaIndex+0.5)*(gammaMax-gammaMin)/nGammaBins + gammaMin;
        PowerLawFlux testFlux(1,testGamma);  //  1 GeV^-1 cm^-2 s^-1;  index = testGamma
        FluxBase *myFluxPtr = &testFlux;
 
        I3PointGenerator i3point(sourceEvents, *myFluxPtr, srcLocations[srcIndex], ark40.livetime);
        srcWeight = i3point->GetMeanSrcNev();
        //srcWeight = 1;
        //cout <<srcIndex<<"  "<<gammaIndex<<"  "
        //     <<testGamma<<"  "<<srcWeight*pdfEnhancements[srcIndex]<< endl;
        srcWeightsArray40[srcIndex].push_back(srcWeight*pdfEnhancements[srcIndex]);
      }
 
    }

    // Normalize each row for sanity's sake (stacking method does not require this)
    cout << endl;
    cout << "Normalized table of Src Weights for different gamma:" << endl;
    cout << "x-axis = Source Index, y-axis = gamma index (soft to hard)"<<endl;
    cout << endl;
    for ( int gammaIndex=0; gammaIndex<nGammaBins; gammaIndex++) {
      printf("%02d:  ",gammaIndex);
      //cout << gammaIndex << ": ";
      double sumRow = 0;
      // Find norm constant
      for (int srcIndex=0; srcIndex<vSize; srcIndex++){
        sumRow += srcWeightsArray40[srcIndex][gammaIndex];
      }
      // And normalize
      for (int srcIndex=0; srcIndex<vSize; srcIndex++){
        srcWeightsArray40[srcIndex][gammaIndex]/=sumRow;
        printf("%.4f ",srcWeightsArray40[srcIndex][gammaIndex]);
      }
 
      cout << endl;
 
    }
    vector<vector<double> > srcWeightsArray59;
    int vSize = srcLocations.size();
    srcWeightsArray59.resize( vSize );
    double srcWeight=0, testGamma=0;
    for (int srcIndex=0; srcIndex < srcLocations.size(); srcIndex++) {
 
      evLoader59.LoadSourceEvents(sourceEvents, srcLocations[srcIndex]);
 
      for ( int gammaIndex=0; gammaIndex<nGammaBins; gammaIndex++) {
        double testGamma = (gammaIndex+0.5)*(gammaMax-gammaMin)/nGammaBins + gammaMin;
        PowerLawFlux testFlux(1,testGamma);  //  1 GeV^-1 cm^-2 s^-1;  index = testGamma
        FluxBase *myFluxPtr = &testFlux;
 
        I3PointGenerator i3point(sourceEvents, *myFluxPtr, srcLocations[srcIndex], ark59.livetime);
        srcWeight = i3point->GetMeanSrcNev();
        //srcWeight = 1;
        //cout <<srcIndex<<"  "<<gammaIndex<<"  "
        //     <<testGamma<<"  "<<srcWeight*pdfEnhancements[srcIndex]<< endl;
        srcWeightsArray59[srcIndex].push_back(srcWeight*pdfEnhancements[srcIndex]);
      }
 
    }

    // Normalize each row for sanity's sake (stacking method does not require this)
    cout << endl;
    cout << "Normalized table of Src Weights for different gamma:" << endl;
    cout << "x-axis = Source Index, y-axis = gamma index (soft to hard)"<<endl;
    cout << endl;
    for ( int gammaIndex=0; gammaIndex<nGammaBins; gammaIndex++) {
      printf("%02d:  ",gammaIndex);
      //cout << gammaIndex << ": ";
      double sumRow = 0;
      // Find norm constant
      for (int srcIndex=0; srcIndex<vSize; srcIndex++){
        sumRow += srcWeightsArray59[srcIndex][gammaIndex];
      }
      // And normalize
      for (int srcIndex=0; srcIndex<vSize; srcIndex++){
        srcWeightsArray59[srcIndex][gammaIndex]/=sumRow;
        printf("%.4f ",srcWeightsArray59[srcIndex][gammaIndex]);
      }
 
      cout << endl;
 
    }

    NewLlhStack newllhstack40;
    newllhstack40.SetUseEnergy(true);
    newllhstack40.SetOptimizeTolerance(0.00);
    newllhstack40.SetMonitorLevel(monLev);
 
    // NEW FOR STACKING
    newllhstack40.SetAnalysisSet(ark40.psData);
    newllhstack40.SetSourceCoords(srcLocations);
    newllhstack40.SetStackedWeightTable(srcWeightsArray40);
    // NEW FOR EXT 
    newllhstack40.SetSourceSigmas(srcSigmas);
 
    NewLlhStack newllhstack59;
    newllhstack59.SetUseEnergy(true);
    newllhstack59.SetOptimizeTolerance(0.00);
    newllhstack59.SetMonitorLevel(monLev);
 
    // NEW FOR STACKING
    newllhstack59.SetAnalysisSet(ark59.psData);
    newllhstack59.SetSourceCoords(srcLocations);
    newllhstack59.SetStackedWeightTable(srcWeightsArray59);
    // NEW FOR EXT 
    newllhstack59.SetSourceSigmas(srcSigmas);
 
 
    MultiAnalysisFn maf;
    //maf.AddAnalysisFn(&newllh22);
    maf.AddAnalysisFn(&newllhstack40);
    maf.AddAnalysisFn(&newllhstack59);
      
   //gROOT->ProcessLine(".L $LAB_MAIN_DIR/macro_llh/ic59/SimpleMultiAnalysis.C");
  
   //EquatorialDeg testSearch(153.375, 11.375);
   //EquatorialDeg testSearch(343.491,16.148);
   
   //mark.SetSource(mySignalPtr);
   ark40.SetSource(srcMod40);
   ark59.SetSource(srcMod59);
   //maf.SetSearchCoord(testSearch); // Not needed for stacking
   
   //MultiAnalysisSet* mas = dynamic_cast<MultiAnalysisSet*>(mark.psData); //already defined
   
   NewLlhEnergy_ParTranslator pt;
   pt.SetRange(1,4,31);
   pt.SetTranslator(mas);
   
   maf.SetParTranslator(&pt);
   
   vector<MinuitParDef> pdv;
   pdv.push_back( MinuitParDef("nSrc",2,0.1, 0.,100.) );
   pdv.push_back( MinuitParDef("gamma",2.5,0.5, 1., 4.) );
   maf.SetParDefs(pdv);
   


  // MAIN LOOP
  //
  ofstream out;
  out.open("stacking/UHECR/teststats_2dof_v2.txt");
  int nTrials = 4000;
  cout << "starting trials" << endl;
  cout << "going for " << nTrials << endl;

  for (int i=0; i<nTrials; ++i) {
	mark.psData->GenerateDataSet_with_nSrcEvents(0);
   	maf.MaximizeLlh();
	out<<maf.GetTestStatistic()<<" "<<maf.GetPar(0)<<" "<<maf.GetPar(1)<<endl;
  } //end of nTrials loop

  out.close();

  //SimpleMultiAnalysis sa;
  //sa.SetNDoF(2);
   
  //cout << "Starting trials" << endl;
  //sa.Execute(mark,maf,1000,0);


  // Disco (Discovery Potential and Sensitivity Estimator)
  /*
  DiscoveryPotential disco;
  gROOT->ProcessLine(".L SetDisco.C");
  // parameters:  loops, optMedianUpperLimit,  significance,  power);
  //SetDisco(disco, 15, false, 2.87e-7, 0.5);
  SetDisco(disco, 30, true, 0.5, 0.9);

  gROOT->ProcessLine(".L MultiDetectionStudy.C");
 
  TCanvas *c = MultiDetectionStudy(mark, maf, mas, disco); //
  */
  /*
  Disco (Discovery Potential and Sensitivity Estimator)
  DiscoveryPotential disco;
  
  gROOT->ProcessLine(".L SetDisco.C");
  // parameters:  loops, optMedianUpperLimit,  significance,  power);
  // SetDisco(disco, 20, false, 2.87e-7, 0.5);
   SetDisco(disco, 30, true, 0.5, 0.9);
  
  gROOT->ProcessLine(".L DetectionZenith.C");

  DetectionZenith dz;
  dz.searchDecDegMin = -85.;   //(skip any bins beyond this range);
  dz.searchDecDegMax = +85.;   //(skip any bins beyond this range);
  dz.nBins = 40;

//  dz.Execute(ark59, newllh59, disco, PowerLawFlux(1,-2));
  dz.Execute(mark, maf, disco, PowerLawFlux(1,-2));
  
  
//  dz.Write("IC59_SC_Zenith.root","recreate");
  dz.Write("IC59_SC_IT2B_Zenith_sensEm2.root","recreate");
//  dz.Write("Multi_BDT_Zenith_sensEm2.root","recreate");

  //dz.Write("IC59_discovery.root","recreate"); //
  */

 
//  return 1; // signal correct finish of script
}
